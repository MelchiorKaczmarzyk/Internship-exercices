{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/oejnhCumJ3jj/oqGJb37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MelchiorKaczmarzyk/Internship-exercices/blob/main/Ex_81_90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 81"
      ],
      "metadata": {
        "id": "ASaRR9ccn2yM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg8P_WZonsKe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "df = pd.read_csv('factory.csv')\n",
        "model = IsolationForest(n_estimators=100, contamination=0.05, random_state = 42)\n",
        "df['outlier_flag'] = model.fit_predict(df)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 82"
      ],
      "metadata": {
        "id": "DYobeWJJn7kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "df = pd.read_csv('factory.csv')\n",
        "model = IsolationForest(n_estimators=100, contamination=0.05, random_state = 42)\n",
        "df['outlier_flag'] = model.fit_predict(df)\n",
        "print(df['outlier_flag'.value_counts()])"
      ],
      "metadata": {
        "id": "piXzYDRRn79G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 83"
      ],
      "metadata": {
        "id": "hhANm-x4n8Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "data, target = load_digits(return_X_y=True)\n",
        "\n",
        "#idx = 250\n",
        "#plt.imshow(data[idx].reshape(8, 8), cmap='gray_r')\n",
        "#plt.title(f'Label: {target[idx]}')\n",
        "#plt.show()\n",
        "print(target[250])"
      ],
      "metadata": {
        "id": "uDILF6Bun9EF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 84"
      ],
      "metadata": {
        "id": "K-uhn1oKn9SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "data, target = load_digits(return_X_y=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data = scaler.fit_transform(data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, target, random_state=42\n",
        ")\n",
        "\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ],
      "metadata": {
        "id": "wBcPnkWUn90D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 85"
      ],
      "metadata": {
        "id": "VhXtLUi1n979"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "data, target = load_digits(return_X_y=True)\n",
        "data = data / data.max()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, target, random_state=42\n",
        ")\n",
        "\n",
        "clasifier = KNeighborsClassifier()\n",
        "clasifier.fit(X_train, y_train)\n",
        "clasifier.predict(X_test)\n",
        "print(f'KNN accuracy: {clasifier.score(X_test, y_test):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BtQXIWon-jX",
        "outputId": "3f756c37-13a9-42f0-9f02-9388a138befa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 86"
      ],
      "metadata": {
        "id": "YoBDc5fVn-2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "data, target = load_digits(return_X_y=True)\n",
        "data = data / data.max()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, target, random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "model.predict(X_test)\n",
        "print(f'Logistic Regression accuracy: {model.score(X_test, y_test):.4f}')"
      ],
      "metadata": {
        "id": "vtQno8nSn_ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 87"
      ],
      "metadata": {
        "id": "awtAyvUEn_h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('data_train.csv')\n",
        "target_train = pd.read_csv('target_train.csv')\n",
        "\n",
        "print(data_train['text'][1])"
      ],
      "metadata": {
        "id": "X1nYBJGCoAKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 88"
      ],
      "metadata": {
        "id": "FaDHCuyOoARw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('data_train.csv')\n",
        "target_train = pd.read_csv('target_train.csv')\n",
        "\n",
        "data_train = data_train['text'].tolist()\n",
        "print(len(data_train))"
      ],
      "metadata": {
        "id": "_Jhj3DXMoA8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 89"
      ],
      "metadata": {
        "id": "io890D6coBEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('data_train.csv')\n",
        "target_train = pd.read_csv('target_train.csv')\n",
        "\n",
        "data_train = data_train['text'].tolist()\n",
        "target_train = target_train.values.ravel()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "data_train_vectorized = vectorizer.fit_transform(data_train)\n",
        "print(data_train_vectorized.shape)"
      ],
      "metadata": {
        "id": "LXbqy7MNoBpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ex 90"
      ],
      "metadata": {
        "id": "qfVCOLPJoBzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('data_train.csv')\n",
        "target_train = pd.read_csv('target_train.csv')\n",
        "\n",
        "categories = ['comp.graphics', 'sci.space']\n",
        "\n",
        "data_train = data_train['text'].tolist()\n",
        "target_train = target_train.values.ravel()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "data_train_vectorized = vectorizer.fit_transform(data_train)\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(data_train_vectorized, target_train)\n",
        "\n",
        "docs = [\n",
        "    'The graphic designer requires a good processor to work',\n",
        "    'Flights into space',\n",
        "]\n",
        "data_new = vectorizer.transform(docs)\n",
        "\n",
        "data_pred = classifier.predict(data_new)\n",
        "\n",
        "for doc, category in zip(docs, data_pred):\n",
        "    print(f'\\'{doc}\\' => {categories[category]}')"
      ],
      "metadata": {
        "id": "dTnxIX9zoC2W"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}